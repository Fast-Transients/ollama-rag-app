# Environment Configuration for HR RAG System
# Copy this file to .env.local for development or .env for production

# Next.js Environment
NODE_ENV=development

# Ollama Configuration
# Default AI model for Q&A (options: gemma3:12b, gpt-oss:20b, gemma3:4b, llama3.2:3b)
DEFAULT_MODEL=gemma3:12b

# Ollama base URL (change if running Ollama on different host/port)
OLLAMA_HOST=http://localhost:11434

# Application Configuration
# Maximum file size for uploads in bytes (default: 50MB)
MAX_FILE_SIZE=52428800

# Maximum number of files per upload (default: 10)
MAX_FILES_PER_UPLOAD=10

# Maximum question length for chat (default: 1000 characters)
MAX_QUESTION_LENGTH=1000

# Vector database configuration
VECTOR_DB_FILE=data/vector-db.json

# File upload directory
UPLOAD_DIR=uploads

# Rate Limiting Configuration
# Upload rate limit: requests per 15 minutes
UPLOAD_RATE_LIMIT_REQUESTS=10
UPLOAD_RATE_LIMIT_WINDOW=900000

# Chat rate limit: requests per minute
CHAT_RATE_LIMIT_REQUESTS=20
CHAT_RATE_LIMIT_WINDOW=60000

# Security Configuration
# CORS settings (development vs production)
# In production, consider setting specific allowed origins
CORS_ORIGIN=*

# Content Security Policy
# Adjust if you need to allow additional sources
CSP_CONNECT_SRC=http://localhost:11434

# Production Deployment
# Set to true when deploying to production
IS_PRODUCTION=false

# Optional: Custom paths for containerized deployment
# DATA_PATH=/app/data
# UPLOADS_PATH=/app/uploads